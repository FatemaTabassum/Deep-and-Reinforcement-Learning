{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "bias = numpy.load(\"softmax_bias.npy\")\n",
    "Weights = numpy.load(\"softmax_weights.npy\")\n",
    "\n",
    "Weights = numpy.reshape(Weights, [100, 20])\n",
    "bias = numpy.reshape(bias, [20, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "asample = numpy.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.0, 0.0, 0.0, 1.606391429901123, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.9543248414993286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.1392189860343933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.0, 0.0, 0.0, 0.0, 0.0, 1.836493968963623, 0.0, \n",
    "                    0.12610933184623718, 0.0, 0.0, 0.0, 0.0843304991722107,\n",
    "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4557386338710785, \n",
    "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.0, 0.0, 0.0, 0.3026450276374817, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.0, 0.0, 0.6092420816421509, 0.23424609005451202, 0.0,\n",
    "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                    0.0, 0.0, 0.0, 0.0]);\n",
    "asample = numpy.reshape(asample, [100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose Weights matrix so that the values of each neuron could be found\n",
    "Weights = Weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of each neurons\n",
    "neurons_value = numpy.dot(Weights, asample) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.30782995e-01]\n",
      " [1.23871563e-03]\n",
      " [1.21610559e-01]\n",
      " [1.46294122e-01]\n",
      " [8.47877610e-03]\n",
      " [2.13691213e-02]\n",
      " [1.51689880e-02]\n",
      " [2.00111944e-02]\n",
      " [1.33690762e-01]\n",
      " [2.57447239e-02]\n",
      " [8.72133367e-03]\n",
      " [4.24674462e-02]\n",
      " [4.01887446e-09]\n",
      " [8.06923030e-02]\n",
      " [6.63685798e-02]\n",
      " [8.49256060e-02]\n",
      " [4.70475825e-02]\n",
      " [2.70795867e-02]\n",
      " [8.18395274e-03]\n",
      " [1.01236478e-02]]\n"
     ]
    }
   ],
   "source": [
    "#Predict output now\n",
    "y_prdict = numpy.exp(neurons_value) / numpy.sum(numpy.exp(neurons_value))\n",
    "print(y_prdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction : \", numpy.argmax(y_prdict) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.03421586]\n"
     ]
    }
   ],
   "source": [
    "# Assuming Class label 1\n",
    "class_label = 1\n",
    "\n",
    "# Cross entropy\n",
    "loss = -numpy.log(y_prdict[class_label-1])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Gradient Descent for Weights\n",
    "\n",
    "gdw = -(y_prdict[class_label-1] - y_prdict[class_label-1]*y_prdict[class_label-1])*asample/y_prdict[class_label-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### QS_ANS_PART_3 ####\n",
    "#Compute Gradient Descent for Bias\n",
    "\n",
    "gdb = -(y_prdict[class_label-1] -\n",
    "            y_prdict[class_label-1]*y_prdict[class_label-1])/y_prdict[class_label-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "Weights_cpy = numpy.copy(Weights)\n",
    "bias_cpy = numpy.copy(bias)\n",
    "\n",
    "Weights_cpy[class_label-1] -= learning_rate*gdw.ravel()\n",
    "bias_cpy[class_label-1] -= learning_rate*gdb.ravel()\n",
    "\n",
    "W_diff = Weights_cpy - Weights\n",
    "B_diff = bias_cpy - bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Weights Increased 10\n",
      "Number of Weights decreased 0\n",
      "Number of Weights Unchanged 1990\n",
      "\n",
      "\n",
      "Number of Biases Increased 1\n",
      "Number of Biases decreased 0\n",
      "Number of Biases Unchanged 19\n"
     ]
    }
   ],
   "source": [
    "increase_w = 0\n",
    "decrease_w = 0\n",
    "increase_b = 0\n",
    "decrease_b = 0\n",
    "no_change_w = 0\n",
    "no_change_b = 0\n",
    "\n",
    "for e in W_diff.ravel():\n",
    "    if(e > 0.001):\n",
    "        increase_w += 1\n",
    "    else:\n",
    "        if(e < -0.001):\n",
    "            decrease_w += 1\n",
    "        else:\n",
    "            no_change_w += 1\n",
    "\n",
    "for e in B_diff.ravel():\n",
    "    if(e > 0.001):\n",
    "        increase_b += 1\n",
    "    else:\n",
    "        if(e < -0.001):\n",
    "            decrease_b += 1\n",
    "        else:\n",
    "            no_change_b += 1 \n",
    "print(\"Number of Weights Increased\",increase_w)\n",
    "print(\"Number of Weights decreased\", decrease_w)\n",
    "print(\"Number of Weights Unchanged\", no_change_w)\n",
    "print(\"\\n\")\n",
    "print(\"Number of Biases Increased\",increase_b)\n",
    "print(\"Number of Biases decreased\", decrease_b)\n",
    "print(\"Number of Biases Unchanged\", no_change_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adverserial Model Prediction:  2\n"
     ]
    }
   ],
   "source": [
    "#### QS_ANS_PART_4 ####\n",
    "\n",
    "inverting_one =numpy.matmul(Weights, Weights.T)\n",
    "\n",
    "inverted_one = numpy.linalg.inv(inverting_one)\n",
    "\n",
    "B = numpy.zeros(20)\n",
    "val = numpy.dot(Weights,asample)+ bias\n",
    "B[1] = val[numpy.argmax(y_prdict)] - val[1]\n",
    "\n",
    "del_x = numpy.matmul(numpy.matmul(Weights.T, inverted_one), B)\n",
    "del_x = numpy.reshape(del_x, [100,1])\n",
    "\n",
    "asample = asample + del_x\n",
    "\n",
    "# predict\n",
    "neurons_value = numpy.dot(Weights, asample) + bias\n",
    "y_prdict = numpy.exp(neurons_value) / numpy.sum(numpy.exp(neurons_value))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Adverserial Model Prediction: \", numpy.argmax(y_prdict) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
