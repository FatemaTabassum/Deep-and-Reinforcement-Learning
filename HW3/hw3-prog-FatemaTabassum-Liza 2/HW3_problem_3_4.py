# -*- coding: utf-8 -*-
"""HW3-Problem_3-4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qv5td03IxqME9LiFkCzSegNGR8lLLyrk
"""

from numpy import mean
from numpy import std
from keras.datasets import mnist
import matplotlib.pyplot as plt
from matplotlib import pyplot
import numpy
from keras.utils import to_categorical
from keras import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from sklearn.model_selection import KFold
from keras.optimizers import SGD
import tensorflow as tf
import keras
from keras.models import Model
from scipy import ndimage
from keras.preprocessing.image import ImageDataGenerator
import random

# --------- All constant values ------------ #

b = numpy.asarray([-1.0, 1.0])

c = numpy.asarray([0.5, -0.5])

W = numpy.asarray([[1.0, -1.0], [0.0, 2.0]])

U = numpy.asarray([[-1.0, 0.0], [1.0, -2.0]])

V = numpy.asarray([[-2.0, 1.0], [-1.0, 0.0]])

x_1 = numpy.asarray([1.0, 0.0])

x_2 = numpy.asarray([0.5, 0.25])

x_3 = numpy.asarray([0.0, 1.0])

def softmax(x):
    """Compute softmax values for each sets of scores in x."""
    e_x = numpy.exp(x)
    return e_x / e_x.sum(axis=0)

def rnn(W, U, V, c, b, x_1, x_2, x_3):

	a_1 = numpy.matmul(U, x_1) + b

	h_1 = numpy.tanh(a_1)

	o_1 = numpy.matmul(V, h_1) + c

	y_1 = softmax(o_1)

	loss_1 = (y_1[0] - 0.5)*(y_1[0] - 0.5) - numpy.log(y_1[1])

	a_2 = numpy.matmul(W, h_1) + numpy.matmul(U, x_2) + b

	h_2 = numpy.tanh(a_2)

	o_2 = numpy.matmul(V, h_2) + c

	y_2 = softmax(o_2)

	loss_2 = (y_2[0] - 0.5)*(y_2[0] - 0.5) - numpy.log(y_2[1])

	a_3 = numpy.matmul(W, h_2) + numpy.matmul(U, x_3) + b

	h_3 = numpy.tanh(a_3)

	o_3 = numpy.matmul(V, h_3) + c

	y_3 = softmax(o_3)

	loss_3 = (y_3[0] - 0.5)*(y_3[0] - 0.5) - numpy.log(y_3[1])

	return ([y_1, y_2, y_3], [loss_1, loss_2, loss_3], [o_1, o_2, o_3])

#---------------------- PROBLEM-3-1 ----------------------#

(y, loss, o) = rnn(W, U, V, c, b, x_1, x_2, x_3)
print("y_1: ", y[0], "\ny_2: ", y[1], "\ny_3: ", y[2])
print("Loss 1: ", loss[0], "\nLoss 2: ", loss[1], "\nLoss 3: ", loss[2])

#---------------------- PROBLEM-3-2 ----------------------#

epsilon= 0.0001
b[0] = b[0] + epsilon
y_b0_i, loss_b0_i, out_rnn = rnn(W, U, V, c, b, x_1, x_2, x_3)
b[0] = b[0] - 2*epsilon
y_b0_d, loss_b0_d, out_rnn = rnn(W, U, V, c, b, x_1, x_2, x_3)
dLdb0 = (loss_b0_i[2] - loss_b0_d[2])/(2*epsilon)
print("dL/db0: ", dLdb0)
b[0] = b[0] + epsilon
b[1] = b[1] + epsilon
y_b1_i, loss_b1_i, out_rnn = rnn(W, U, V, c, b, x_1, x_2, x_3)
b[1] = b[1] - 2*epsilon
y_b1_d, loss_b1_d, out_rnn = rnn(W, U, V, c, b, x_1, x_2, x_3)
dLdb1 = (loss_b1_i[2] - loss_b1_d[2])/(2*epsilon)
print("dL/db1: ", dLdb1)
b[1] = b[1] + epsilon

#---------------------- PROBLEM-3-4 ----------------------#
b[0] -= 0.01*dLdb0
b[1] -= 0.01*dLdb1
print("New B: ", b)

#---------------------- PROBLEM-3-5 ----------------------#

(y, loss, o) = rnn(W, U, V, c, b, x_1, x_2, x_3)
print("y_1: ", y[0], "\ny_2: ", y[1], "\ny_3: ", y[2])
print("Loss 1: ", loss[0], "\nLoss 2: ", loss[1], "\nLoss 3: ", loss[2])

